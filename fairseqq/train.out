nohup: 忽略输入
usage: train.py [-h] [--no-progress-bar] [--log-interval N]
                [--log-format {json,none,simple,tqdm}] [--seed N] [--fp16]
                [--fp16-init-scale FP16_INIT_SCALE] [--task TASK]
                [--skip-invalid-size-inputs-valid-test] [--max-tokens N]
                [--max-sentences N] [--train-subset SPLIT]
                [--valid-subset SPLIT] [--max-sentences-valid N]
                [--distributed-world-size N]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--ddp-backend {c10d,no_c10d}] [--bucket-cap-mb MB] --arch
                ARCH [--criterion CRIT] [--max-epoch N] [--max-update N]
                [--clip-norm NORM] [--sentence-avg] [--update-freq N]
                [--optimizer OPT] [--lr LR_1,LR_2,...,LR_N] [--momentum M]
                [--weight-decay WD]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,reduce_lr_on_plateau,triangular}]
                [--lr-shrink LS] [--min-lr LR] [--min-loss-scale D]
                [--save-dir DIR] [--restore-file RESTORE_FILE]
                [--reset-optimizer] [--reset-lr-scheduler]
                [--optimizer-overrides DICT] [--save-interval N]
                [--save-interval-updates N] [--keep-interval-updates N]
                [--no-save] [--no-epoch-checkpoints] [--validate-interval N]
train.py: error: argument --distributed-world-size: expected one argument
